{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Technical Report Notebook 4\n",
    "\n",
    "### Modelling Extension - Hailstorm Severity + Earthquake Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.A. Severity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import modelling libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hail_tweet_text = pd.read_csv(\"./hail_tweet_text.csv\")\n",
    "hail_tweet_text.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4786, 1028)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Create hail and earthquake classes\n",
    "\n",
    "hail_tweet_text_hail = hail_tweet_text.ix[hail_tweet_text['hail'] > 0]                            \n",
    "\n",
    "hail_tweet_text_hail['event_class'] = 0\n",
    "\n",
    "hail_tweet_text_hail.ix[hail_tweet_text_hail['Cat_ID'] == 144, 'event_class'] = 1\n",
    "\n",
    "print(hail_tweet_text_hail.shape)\n",
    "\n",
    "y_hail = hail_tweet_text_hail['event_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4786, 1002)\n",
      "(4786, 992)\n"
     ]
    }
   ],
   "source": [
    "hail_tweets = hail_tweet_text_hail.ix[:,26:]\n",
    "print (hail_tweets.shape)\n",
    "\n",
    "hail_tweets.drop(hail_tweets[['hail','hailstorm','event_class','australia','bnestorm','queensland','sydney','sydneystorm','brisbane','brisbanestorm']], axis=1, inplace=True)\n",
    "print (hail_tweets.shape)\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xs_hail_total = ss.fit_transform(hail_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(Xs_hail_total)\n",
    "X_hail = tf_transformer.transform(Xs_hail_total)\n",
    "\n",
    "X_train_hail, X_test_hail, y_train_hail, y_test_hail = train_test_split(X_hail, y_hail, test_size=0.8)\n",
    "\n",
    "rfc_hail = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "# Extract the top features from the decision tree classifier.\n",
    "rfc_hail.fit(X_train_hail, y_train_hail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>chaos</td>\n",
       "      <td>0.029449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>storm</td>\n",
       "      <td>0.026837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.022198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>super</td>\n",
       "      <td>0.019924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ball</td>\n",
       "      <td>0.018387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>massive</td>\n",
       "      <td>0.017496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>worst</td>\n",
       "      <td>0.015561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>golf</td>\n",
       "      <td>0.013815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>car</td>\n",
       "      <td>0.009927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>smashed</td>\n",
       "      <td>0.009533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>powerful</td>\n",
       "      <td>0.009351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>today</td>\n",
       "      <td>0.009092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>causes</td>\n",
       "      <td>0.008767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>day</td>\n",
       "      <td>0.007462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>windows</td>\n",
       "      <td>0.007108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>qld</td>\n",
       "      <td>0.006919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>thousands</td>\n",
       "      <td>0.006712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>inside</td>\n",
       "      <td>0.006554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>work</td>\n",
       "      <td>0.006323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>slammed</td>\n",
       "      <td>0.006067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "139      chaos    0.029449\n",
       "798      storm    0.026837\n",
       "991  sentiment    0.022198\n",
       "819      super    0.019924\n",
       "45        ball    0.018387\n",
       "504    massive    0.017496\n",
       "973      worst    0.015561\n",
       "319       golf    0.013815\n",
       "117        car    0.009927\n",
       "762    smashed    0.009533\n",
       "646   powerful    0.009351\n",
       "876      today    0.009092\n",
       "129     causes    0.008767\n",
       "191        day    0.007462\n",
       "959    windows    0.007108\n",
       "660        qld    0.006919\n",
       "861  thousands    0.006712\n",
       "397     inside    0.006554\n",
       "969       work    0.006323\n",
       "758    slammed    0.006067"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the top features from the decision tree classifier.\n",
    "\n",
    "top_features_rfc_hail = pd.DataFrame({\n",
    "        'feature':hail_tweets.columns,\n",
    "        'importance':rfc_hail.feature_importances_})\n",
    "\n",
    "top_features_rfc_hail.sort_values('importance', ascending=False, inplace=True)\n",
    "top_features_rfc_hail.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82245431  0.79634465  0.79634465  0.7767624   0.80130719]\n",
      "0.798642638953\n",
      "confusion matrix\n",
      "          pred_severe  pred_moderate\n",
      "severe            698            682\n",
      "moderate          200           2249\n",
      "--------\n",
      "accuracy: 0.769652650823\n",
      "--------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84      2449\n",
      "          1       0.78      0.51      0.61      1380\n",
      "\n",
      "avg / total       0.77      0.77      0.76      3829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_hail_scores = cross_val_score(rfc_hail, X_test_hail, y_test_hail, cv=5)\n",
    "\n",
    "print (rfc_hail_scores)\n",
    "print (sum(rfc_hail_scores)/len(rfc_hail_scores))\n",
    "\n",
    "# Create predicted y values\n",
    "\n",
    "yhat_test_rfc_hail = rfc_hail.predict(X_test_hail)\n",
    "yhat_test_rfc_hail_pp = rfc_hail.predict_proba(X_test_hail)\n",
    "\n",
    "# convert the predicted and actual values to a confusion array\n",
    "\n",
    "confusion_array_rfc = confusion_matrix(y_test_hail, yhat_test_rfc_hail, labels=[1,0])\n",
    "\n",
    "confusion_rfc = pd.DataFrame(confusion_array_rfc, index=['severe','moderate'],\n",
    "                         columns=['pred_severe','pred_moderate'])\n",
    "\n",
    "print (\"confusion matrix\")\n",
    "print (confusion_rfc)\n",
    "print (\"--------\")\n",
    "print (\"accuracy:\", accuracy_score(y_test_hail, yhat_test_rfc_hail)) # accuracy = (tp + tn) / total_population)\n",
    "print (\"--------\")\n",
    "print (classification_report(y_test_hail, yhat_test_rfc_hail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.B. Catastrophe Modelling - _Introducing Earthquake_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Setting up the classification exercise with earthquake and hail classes (0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hail_tweet_text = pd.read_csv(\"./hail_tweet_text.csv\")\n",
    "hail_tweet_text.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create hail and earthquake classes\n",
    "\n",
    "hail_tweet_text['catastrophe_class'] = 0\n",
    "\n",
    "hail_tweet_text.ix[hail_tweet_text['hail'] >= 1, 'catastrophe_class'] = 1\n",
    "hail_tweet_text.ix[hail_tweet_text['hailstorm'] >= 1, 'catastrophe_class'] = 1\n",
    "\n",
    "hail_tweet_text.ix[hail_tweet_text['earthquake'] >= 1, 'catastrophe_class'] = 2\n",
    "hail_tweet_text.ix[hail_tweet_text['quake'] >= 1, 'catastrophe_class'] = 2\n",
    "\n",
    "y_total = hail_tweet_text['catastrophe_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127989, 1002)\n",
      "(127989, 997)\n"
     ]
    }
   ],
   "source": [
    "htt_total = hail_tweet_text.ix[:,26:]\n",
    "print (htt_total.shape)\n",
    "\n",
    "htt_total.drop(htt_total[['hail','hailstorm','earthquake','quake','catastrophe_class']], axis=1, inplace=True)\n",
    "print (htt_total.shape)\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xs_htt_total = ss.fit_transform(htt_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(htt_total)\n",
    "X_total_tf = tf_transformer.transform(htt_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_total_tf, y_total, test_size=0.5)\n",
    "\n",
    "rfc_total = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "# Extract the top features from the decision tree classifier.\n",
    "rfc_total.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95320678  0.95234003  0.95507462  0.95186748  0.94991405]\n",
      "0.952480590171\n"
     ]
    }
   ],
   "source": [
    "rfc_scores = cross_val_score(rfc_total, X_test, y_test, cv=5)\n",
    "\n",
    "print (mnb_scores)\n",
    "print (sum(mnb_scores)/len(mnb_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_eq</th>\n",
       "      <th>pred_hail</th>\n",
       "      <th>pred_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eq</th>\n",
       "      <td>2248</td>\n",
       "      <td>2</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hail</th>\n",
       "      <td>0</td>\n",
       "      <td>1108</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no cat</th>\n",
       "      <td>263</td>\n",
       "      <td>232</td>\n",
       "      <td>58303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_eq  pred_hail  pred_no\n",
       "eq         2248          2      526\n",
       "hail          0       1108     1313\n",
       "no cat      263        232    58303"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create predicted y values\n",
    "\n",
    "yhat_test_rfc = rfc_total.predict(X_test)\n",
    "yhat_test_rfc_pp = rfc_total.predict_proba(X_test)\n",
    "\n",
    "# convert the predicted and actual values to a confusion array\n",
    "\n",
    "confusion_array_rfc = confusion_matrix(y_test, yhat_test_rfc, labels=[2,1,0])\n",
    "\n",
    "confusion_mnb = pd.DataFrame(confusion_array_rfc, index=['eq', 'hail','no cat'],\n",
    "                         columns=['pred_eq','pred_hail', 'pred_no'])\n",
    "confusion_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    58798\n",
       "2     2776\n",
       "1     2421\n",
       "Name: catastrophe_class, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(yhat_test_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
